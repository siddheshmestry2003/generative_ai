{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b0de7b",
   "metadata": {},
   "source": [
    "# ChatBoat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b36b1",
   "metadata": {},
   "source": [
    "##### we are go over an example of how to design and implement an LLM - powered chatbot.This chatbot will be able to have a conversation and remember previous interactions.\n",
    "##### note this chatbot that will only use the language model to have a conversation.there are several other related concept that you may be looking for:\n",
    "\n",
    "##### * conversation RAG:enable a chatbot experience over an external source of data\n",
    "\n",
    "##### * Agent: Build a chatBot that can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd99b47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"groq_api_key\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2568a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020049C35870>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020049C35780>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659b1ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Siddhesh! As a data analyst aspirant, you're taking the first step towards a fascinating career path. Data analysis is a crucial aspect of decision-making in various industries, and the demand for data analysts is on the rise.\\n\\nWhat specific areas of data analysis are you interested in, or what do you want to achieve as a data analyst? Are you looking to:\\n\\n1. Work in a specific industry (e.g., finance, healthcare, marketing)?\\n2. Gain a strong foundation in statistical modeling and machine learning?\\n3. Develop expertise in data visualization and storytelling?\\n4. Explore tools like Excel, SQL, Python, R, or Tableau?\\n5. Something else?\\n\\nFeel free to share your goals, and I'll do my best to provide guidance and resources to help you on your journey!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 48, 'total_tokens': 216, 'completion_time': 0.242718391, 'prompt_time': 0.002761615, 'queue_time': 0.049638205, 'total_time': 0.245480006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--c4d8ff06-90f3-4114-8cf5-ff3c232a75de-0', usage_metadata={'input_tokens': 48, 'output_tokens': 168, 'total_tokens': 216})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"hi,i am siddhesh and iam aspirant data analyst\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59260c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Siddhesh, and you are an aspirant Data Analyst.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 89, 'total_tokens': 106, 'completion_time': 0.033081017, 'prompt_time': 0.007876673, 'queue_time': 0.048513947, 'total_time': 0.04095769}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--735aac5c-8a08-4339-921f-ad631c1f900a-0', usage_metadata={'input_tokens': 89, 'output_tokens': 17, 'total_tokens': 106})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hi,i am siddhesh and iam aspirant data analyst\"),\n",
    "        AIMessage(content=\"hello siddhesh ! it's nice to meet you. \\n\\n as a data anslyst\"),\n",
    "        HumanMessage(content=\"hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ca1e3",
   "metadata": {},
   "source": [
    "### Message History\n",
    "we can use a message history class to wrap our model and make it startful. this will keep track of input and output of the model and store them in some datastore. Future interactions will then load those messages and pss them into the chain as part of the input .let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f028fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory: # to save session of each and every use seperate \n",
    "    if session_id not in store:\n",
    "          store[session_id]=ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff13c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfcbb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " response=with_message_history.invoke(\n",
    "\n",
    "    \n",
    "    [\n",
    "        HumanMessage(content=\"Hi , my name is Siddhesh and i am a data analyst\")\n",
    "      \n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8523c4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you've told me your profession twice already. No worries, I'm happy to chat with you about anything related to data analysis or your work.\\n\\nIf you'd like, we could discuss some popular topics in data analysis, such as:\\n\\n1. Data visualization tools (e.g., Tableau, Power BI, D3.js)\\n2. Machine learning algorithms and their applications\\n3. Data warehousing and ETL (Extract, Transform, Load) processes\\n4. Statistical analysis and hypothesis testing\\n5. Data storytelling and communication techniques\\n\\nLet me know if any of these topics interest you, or if you'd rather talk about something else.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3496522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Siddhesh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 427, 'total_tokens': 435, 'completion_time': 0.003808798, 'prompt_time': 0.025630664, 'queue_time': 0.054890776, 'total_time': 0.029439462}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--47514e86-d848-4b09-8f3d-af05b386c347-0', usage_metadata={'input_tokens': 427, 'output_tokens': 8, 'total_tokens': 435})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "\n",
    "    \n",
    "    [\n",
    "        HumanMessage(content=\"what is my name?\")\n",
    "      \n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b4f9335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Sagar. What subject are you studying, and what level are you in (high school, undergraduate, or graduate)?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 45, 'total_tokens': 75, 'completion_time': 0.0627752, 'prompt_time': 0.002653312, 'queue_time': 0.049160927, 'total_time': 0.065428512}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e7f5db2c-ec44-4231-8857-3d19a673a4f1-0', usage_metadata={'input_tokens': 45, 'output_tokens': 30, 'total_tokens': 75})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create another session id call as chat2 and new configuratin\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "\n",
    "new_response=with_message_history.invoke(\n",
    "\n",
    "    \n",
    "    [\n",
    "        HumanMessage(content=\" my name is sagar and i am a student\")\n",
    "      \n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "new_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72921df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Sagar, a student. I'm glad to be having a conversation with you. What would you like to talk about?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 130, 'total_tokens': 158, 'completion_time': 0.050399646, 'prompt_time': 0.007067644, 'queue_time': 0.048576836, 'total_time': 0.05746729}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--67940648-f983-4ce0-a9c2-cc7fe681ee02-0', usage_metadata={'input_tokens': 130, 'output_tokens': 28, 'total_tokens': 158})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_response=with_message_history.invoke(\n",
    "\n",
    "    \n",
    "    [\n",
    "        HumanMessage(content=\" who am i?\")\n",
    "      \n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "new_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8469e8",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "Prompts templates help to turn raw user information into as format thtat the LLm can work with. In this case the raw user input is just a message ,which we are passing to the LLM .\n",
    "lets now make that a bit more complicated. first,lets add in a system message with some custom instructions(but still taking messagees as input). Next we will add in more input besides just the messsages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "548431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant .Answer all question to the best of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f2b9463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Siddhesh! I'm an assistant here to help with any questions or topics you'd like to discuss. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 59, 'total_tokens': 95, 'completion_time': 0.051854808, 'prompt_time': 0.003150316, 'queue_time': 0.049513983, 'total_time': 0.055005124}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7fe37df9-fe76-4c9f-b0ae-3970fea495dc-0', usage_metadata={'input_tokens': 59, 'output_tokens': 36, 'total_tokens': 95})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is siddhesh\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "504b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_with_message_history=RunnableWithMessageHistory(chain,get_session_history=get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c30ca4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a helpful assistant, and our conversation just started. I don't have the ability to retain or access any information about individual users, including their names. Each time you interact with me, it's a new conversation. If you'd like to share your name with me, I'm happy to chat with you!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 115, 'total_tokens': 190, 'completion_time': 0.097140045, 'prompt_time': 0.006470984, 'queue_time': 0.050132575, 'total_time': 0.103611029}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--cc68c5ce-dfcf-422f-bb13-316ca50b116c-0', usage_metadata={'input_tokens': 115, 'output_tokens': 75, 'total_tokens': 190})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={'configurable':{\"session_id\":\"chat3\"}}\n",
    "response_3=new_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config2\n",
    ")\n",
    "response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc74b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526cf37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c6bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more complexicity\n",
    "\n",
    "prompt1=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant .Answer all question to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain1=prompt1|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "018b7ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते सिद्धेश जी, मैं आपकी सहायता के लिए यहाँ हूँ। आपके प्रश्न का उत्तर देने की कोशिश करूँगा। क्या आप कुछ पूछना चाहते हैं, या कोई समस्या का समाधान चाहते हैं?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce4=chain1.invoke({\"messages\":[HumanMessage(content=\"hi , my name is siddhesh\")],\"language\":\"hindi\"})\n",
    "responce4.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9deff3",
   "metadata": {},
   "source": [
    "lets noe wrap this more complidated chain n a messge Hstory class.  This time,because there are multiple keys in the imput we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51ca6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_with_message_history_1=RunnableWithMessageHistory(\n",
    "    chain1,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6b2400d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते श्री जी, मैं आपकी मदद करने के लिए यहाँ हूँ। क्या आपके पास कोई प्रश्न है जिस पर मैं आपकी सहायता कर सकता हूँ?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "\n",
    "\n",
    "\n",
    "response4=new_with_message_history_1.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"hi, i am shree\")],\"language\":\"hindi\"},\n",
    "    config3\n",
    "    )\n",
    "\n",
    "response4.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90110ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तुम्हारा नाम श्री है।'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4=new_with_message_history_1.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what is my name\")],\"language\":\"hindi\"},\n",
    "    config3\n",
    "    )\n",
    "\n",
    "response4.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfa21d",
   "metadata": {},
   "source": [
    "## Mangage the conversation History\n",
    "\n",
    "x one important concept to understand when building chatboat is  how to manage conversation history .if left unmanaged the list of messages will grow unbounded and potentially overflow the context window of the LLM, therefore m it is  important to add a step that limits the size of the messages you are passing in,\n",
    "\n",
    "Trim_message=it is helper to resuce how many messages we are sending to the model. The trimmer allows us to specigy how many tokens we want to keep alone with other parametes like if we want ot always keep the system messages and wheteher to allow partial messsages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbe190ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "# sample conversation\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\")\n",
    "]\n",
    "\n",
    "# use this messages to tream\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f79c767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आइस क्रीम बहुत स्वादिष्ट होती है! आपको यह पसंद है क्या?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "|prompt1\n",
    "|model\n",
    ")\n",
    "\n",
    "responce=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what is ice cream do i like\")],\n",
    "    \"language\":\"hindi\"\n",
    "    }\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71ccab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप ने 2 + 2 का सवाल पूछा था।'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what math problem did i adk\")],\n",
    "    \"language\":\"hindi\"\n",
    "    }\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90ebd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap this in the messge histry\n",
    "with_message_history_2=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "\n",
    ")\n",
    "config4={\"configurable\":{\"session_id\":\"chat6\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9581eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते सिद्धेश जी, मैं आपकी सहायता के लिए यहाँ हूँ। आपके प्रश्न का उत्तर देने की कोशिश करूँगा। क्या आप कुछ पूछना चाहते हैं, या कोई समस्या का समाधान चाहते हैं?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response5=with_message_history_2.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what math problem did i ask\")],\n",
    "     \"language\":\"hindi\"\n",
    "     },\n",
    "     config=config4\n",
    ")\n",
    "\n",
    "responce4.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c8d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
