{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198a6647",
   "metadata": {},
   "source": [
    "# simple Gen AI APP Using  Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea51ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup key environment\n",
    "import  os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "# langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"True\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7119a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# data ingeston :- from the website we need to scrap the data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a3c384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x21c77c77be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25b3fa",
   "metadata": {},
   "source": [
    "### steps\n",
    " ###### laod data->docs-> divide our text inot chunks -> text -> vector -> vector embedding -> store in vectorstore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d097d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to Langsmith - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoursesDSA / PlacementsGATE 2026 PrepML & Data ScienceDevelopmentCloud / DevOpsProgramming LanguagesAll CoursesTutorialsPythonJavaDSAML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentGATECS SubjectsDevOpsSchool LearningSoftware and ToolsPracticePractice Coding ProblemsNation Skillup- Free CoursesProblem of the DayBuild AI Agent (Free)StudyIn: Global ContestJobsApply Now!Post JobsJobs Updates\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\nMark all as read\\n\\n\\n\\n\\n\\nAll\\n\\n\\n\\n\\n\\n \\n\\nView All\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\n\\n\\nMark all as read\\n\\n\\n\\n\\n\\n\\nAll\\n\\n\\nUnread\\n\\n\\nRead\\n\\n\\n\\n\\n\\r\\n                        You\\'re all caught up!!\\r\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLP TutorialLibrariesPhasesText PreprosessingTokenizationLemmatizationWord EmbeddingsProjects IdeasInterview QuestionNLP QuizNLP PipelineDL for NLPNLP DatasetsMachine Learning \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign In\\n\\n\\n▲\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExplore GfG Connect NewShare Your ExperiencesNatural Language Processing (NLP) TutorialIntroduction to NLPNatural Language Processing (NLP) - OverviewNLP vs NLU vs NLGApplications of NLPWhy is NLP important?Phases of Natural Language Processing (NLP)The Future of Natural Language Processing: Trends and InnovationsLibraries for NLPNLTK - NLPTokenization Using SpacyPython | Tokenize text using TextBlobIntroduction to Hugging Face TransformersNLP Gensim Tutorial - Complete Guide For BeginnersNLP Libraries in PythonText Normalization in NLPNormalizing Textual Data with PythonRegex Tutorial - How to write Regular Expressions?Tokenization in NLPLemmatization with NLTKIntroduction to StemmingRemoving stop words with NLTK in PythonPOS(Parts-Of-Speech) Tagging in NLPText Representation and Embedding TechniquesOne-Hot Encoding in NLPBag of words (BoW) model in NLPUnderstanding TF-IDF (Term Frequency-Inverse Document Frequency)N-Gram Language Modelling with NLTKWord Embedding using Word2VecGlove Word Embedding in NLPOverview of Word Embedding using Embeddings from Language Models (ELMo)NLP Deep Learning TechniquesNLP with Deep LearningIntroduction to Recurrent Neural NetworksWhat is LSTM - Long Short Term Memory?Gated Recurrent Unit NetworksTransformers in Machine Learningseq2seq ModelTop 5 PreTrained Models in Natural Language Processing (NLP)NLP Projects and PracticeSentiment Analysis with an Recurrent Neural Networks (RNN)Text Generation using Recurrent Long Short Term Memory NetworkMachine Translation with Transformer in PythonBuilding a Rule-Based Chatbot with Natural Language ProcessingText Classification using scikit-learn in NLPText Summarization using HuggingFace ModelNatural Language Processing Interview QuestionData Science LiveCourse \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to Langsmith\\n\\n\\n\\nLast Updated : \\n23 Jul, 2025\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\n\\n1 Likes\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangsmith is a framework designed to enhance and streamline the development of natural language processing (NLP) applications. It builds upon LangChain, a popular library for chaining multiple language models together, to create complex and flexible NLP workflows. Langsmith provides tools for managing, deploying, and scaling NLP applications efficiently.What is Langsmith?Langsmith is a comprehensive solution for developers and data scientists working with NLP models. It offers a robust environment for creating, testing and deploying language models in a maintainable manner. By leveraging LangChain\\'s capabilities, Langsmith simplifies the process of chaining multiple language models and other NLP components to build powerful applications.Key Features of Langsmith:Model Management: Easily manage multiple versions of your language models, track their performance and update them seamlessly.Workflow Structure: Design complex NLP workflows using a visual interface or code, enabling the integration of various models and services.Deployment: Deploy models and workflows to different environments with minimal configuration.Scalability: Scale your applications horizontally to handle large data and requests.Monitoring and Logging: Keep track of model performance, usage statistics, and error logs for better observability.Integration with LangChainLangChain is a core component of Langsmith. It provides the foundational capabilities for chaining multiple language models. By integrating LangChain, Langsmith allows developers to create intricate NLP workflows that can perform various tasks, from text generation to sentiment analysis.Example: Building a Simple NLP Workflow1. Importing and Initializing Langchain\\nPython\\n\\nfrom langchain import LangChain\\nchain = LangChain()\\n\\n2. Added Language ModelsTwo models are added:\\'gpt-3\\' : A generative model\\'sentiment-analysis\\' : A classifier model\\nPython\\n\\nchain.add_model(\\'gpt-3\\', \\'text-davinci-003\\')\\nchain.add_model(\\'sentiment-analysis\\', \\'distilbert-base-uncased\\')\\n\\n3. Initializing LangsmithLangsmith is initialized by wrapping around the LangChain workflow.It adds functionalities like logging, monitoring, version control etc.\\nPython\\n\\nfrom langsmith import Langsmith\\nsmith = Langsmith(chain)\\n\\n4. Defining the NLP Workflow\\nPython\\n\\ndef nlp_workflow(text):\\n    generated_text = smith.run_model(\\'gpt-3\\', text)\\n    sentiment = smith.run_model(\\'sentiment-analysis\\', generated_text)\\n    return generated_text, sentiment\\n\\n5. Testing the workflow and Printing results\\nPython\\n\\ntext = \"Langsmith is revolutionizing NLP development!\"\\ngenerated_text, sentiment = nlp_workflow(text)\\n\\nprint(f\"Generated Text: {generated_text}\")\\nprint(f\"Sentiment: {sentiment}\")\\n\\nOutput:Generated Text: \"Indeed, the advancements in NLP tools like Langsmith are paving the way for more efficient and effective language processing solutions, enhancing the capabilities of various applications.\"Sentiment: PositiveRelated Tools: LangGraph, LangFlow, LangServe, and LangFuseLangsmith is part of a broader ecosystem of tools designed to work together to enhance NLP workflows. Here’s a detailed look at these related tools:LangGraphLangGraph is a visualization tool that allows developers to explore and analyze the structure of language models and their workflows. With LangGraph, you can:Visualize Model Relationships: Understand how different models and components in your workflow are interconnected.Track Data Flow: See how data moves through the workflow, from input to output, and identify potential bottlenecks or inefficiencies.Debug and Optimize: Use visual insights to debug issues and optimize the performance of your NLP workflows.LangFlowIt is a workflow automation tool that integrates seamlessly with Langsmith, enabling developers to design, manage and automate complex NLP workflows through a visual interface. LangFlow’s features include:Drag-and-Drop Interface: Easily create and modify workflows using a user-friendly drag-and-drop interface.Pre-Built Templates: Access a library of pre-built templates for common NLP tasks, speeding up the development process.Real-Time Monitoring: Monitor the performance and status of your workflows in real time, allowing for immediate adjustments and improvements.LangServeLangServe is a deployment tool specifically designed for serving NLP models and workflows in production environments. With LangServe, you can:Deploy at Scale: Efficiently deploy models to handle high volumes of requests, ensuring robust and scalable NLP applications.Manage Deployments: Easily manage multiple deployments, track their performance, and update models without downtime.Secure and Reliable: Ensure the security and reliability of your deployed models with built-in features for authentication, authorization, and monitoring.LangFuseLangFuse is a tool for integrating multiple NLP models and services, enabling seamless interoperability across different components. LangFuse offers:Unified API: Provide a unified API to integrate various NLP models and services, simplifying the development process.Flexible Integration: Support for integrating models from different frameworks and languages, making it easier to build comprehensive NLP solutions.Enhanced Collaboration: Facilitate collaboration among team members by providing a centralized platform for managing and accessing integrated models.Applications of LangsmithLangsmith, with its framework and integration capabilities, has a wide range of applications across various industries. By leveraging Langsmith, organizations can build sophisticated NLP solutions that streamline operations, enhance user experiences and drive innovation. Here are some key applications of Langsmith:1. Customer Support and ChatbotsLangsmith can be used to develop intelligent customer support systems and chatbots that provide accurate responses to customer queries.Build chatbots that can handle common customer inquiries, reducing the need for human intervention and improving response times.2. Content Generation and SummarizationLangsmith\\'s capabilities in text generation make it an excellent tool for content creation and summarization.Generating high-quality articles, blog posts and reports automatically, saving time and resources.3. Healthcare and Medical ResearchIn the healthcare industry, Langsmith can be used to process and analyze vast amounts of medical data, aiding in research and patient care.Analyzing patient records to extract valuable insights, identify patterns, and assist in diagnosis.4. Finance and BankingLangsmith can enhance various financial services by providing intelligent solutions for data analysis, customer interaction, and risk management.Analyzing transaction data to identify suspicious activities and potential fraud in real time.5. E-commerce and RetailIn the e-commerce and retail sector, Langsmith can improve customer experiences and streamline operations.Develop recommendation systems that suggest products based on customer behavior and preferences.Langsmith offers a powerful and flexible environment for developing and deploying NLP applications. By building on LangChain\\'s capabilities, Langsmith provides a comprehensive solution for managing the entire lifecycle of NLP models, from development to deployment.  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Quiz\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Comment\\r\\n    \\n\\n\\n\\n\\n\\nY\\n\\n\\n\\n\\n\\nyashdkadam\\n\\n\\n\\n\\n\\n Follow\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\nImprove\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nY\\n\\n\\n\\n\\n \\n\\nyashdkadam \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\nArticle Tags : \\n\\n\\nNLP\\n\\n\\nAI-ML-DS\\n\\n\\nArtificial Intelligence\\n\\n\\nAI-ML-DS With Python\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n356k+ interested Geeks \\n\\n\\n\\nData Structures & Algorithms in Python - Self Paced \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4k+ interested Geeks \\n\\n\\n\\nGATE CS/IT 2027 Complete Course [with Placement Preparation] \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10k+ interested Geeks \\n\\n\\n\\nGATE 2027 - CS & IT  (Live + Recorded) \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate & Communications Address:\\n\\r\\n                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \\n\\n\\n\\n\\n\\nRegistered Address:\\r\\n                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalPrivacy PolicyCareersContact UsCorporate SolutionCampus Training ProgramExplorePOTDJob-A-ThonConnectBlogsNation Skill UpTutorialsProgramming LanguagesDSAWeb TechnologyAI, ML & Data ScienceDevOpsCS Core SubjectsGATESchool SubjectsSoftware and ToolsCoursesIBM CertificationDSA and PlacementsWeb DevelopmentData ScienceProgramming LanguagesDevOps & CloudGATETrending TechnologiesOffline CentersNoidaBengaluruPuneHyderabadPatnaPreparation CornerInterview CornerAptitudePuzzlesGfG 160System Design \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\nmin 4 words, max Words Limit:1000\\n\\n\\n\\n\\nThank You!\\nYour suggestions are valuable to us.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make document\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43065bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"Introduction to Langsmith - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoursesDSA / PlacementsGATE 2026 PrepML & Data ScienceDevelopmentCloud / DevOpsProgramming LanguagesAll CoursesTutorialsPythonJavaDSAML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentGATECS SubjectsDevOpsSchool LearningSoftware and ToolsPracticePractice Coding ProblemsNation Skillup- Free CoursesProblem of the DayBuild AI Agent (Free)StudyIn: Global ContestJobsApply Now!Post JobsJobs Updates\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\nMark all as read\\n\\n\\n\\n\\n\\nAll\\n\\n\\n\\n\\n\\n \\n\\nView All\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\n\\n\\nMark all as read\\n\\n\\n\\n\\n\\n\\nAll\\n\\n\\nUnread\\n\\n\\nRead\\n\\n\\n\\n\\n\\r\\n                        You're all caught up!!\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"All\\n\\n\\n\\n\\n\\n \\n\\nView All\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\n\\n\\nMark all as read\\n\\n\\n\\n\\n\\n\\nAll\\n\\n\\nUnread\\n\\n\\nRead\\n\\n\\n\\n\\n\\r\\n                        You're all caught up!!\\r\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLP TutorialLibrariesPhasesText PreprosessingTokenizationLemmatizationWord EmbeddingsProjects IdeasInterview QuestionNLP QuizNLP PipelineDL for NLPNLP DatasetsMachine Learning \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign In\\n\\n\\n▲\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Explore GfG Connect NewShare Your ExperiencesNatural Language Processing (NLP) TutorialIntroduction to NLPNatural Language Processing (NLP) - OverviewNLP vs NLU vs NLGApplications of NLPWhy is NLP important?Phases of Natural Language Processing (NLP)The Future of Natural Language Processing: Trends and InnovationsLibraries for NLPNLTK - NLPTokenization Using SpacyPython | Tokenize text using TextBlobIntroduction to Hugging Face TransformersNLP Gensim Tutorial - Complete Guide For BeginnersNLP Libraries in PythonText Normalization in NLPNormalizing Textual Data with PythonRegex Tutorial - How to write Regular Expressions?Tokenization in NLPLemmatization with NLTKIntroduction to StemmingRemoving stop words with NLTK in PythonPOS(Parts-Of-Speech) Tagging in NLPText Representation and Embedding TechniquesOne-Hot Encoding in NLPBag of words (BoW) model in NLPUnderstanding TF-IDF (Term Frequency-Inverse Document Frequency)N-Gram Language Modelling with NLTKWord Embedding using Word2VecGlove'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='TechniquesOne-Hot Encoding in NLPBag of words (BoW) model in NLPUnderstanding TF-IDF (Term Frequency-Inverse Document Frequency)N-Gram Language Modelling with NLTKWord Embedding using Word2VecGlove Word Embedding in NLPOverview of Word Embedding using Embeddings from Language Models (ELMo)NLP Deep Learning TechniquesNLP with Deep LearningIntroduction to Recurrent Neural NetworksWhat is LSTM - Long Short Term Memory?Gated Recurrent Unit NetworksTransformers in Machine Learningseq2seq ModelTop 5 PreTrained Models in Natural Language Processing (NLP)NLP Projects and PracticeSentiment Analysis with an Recurrent Neural Networks (RNN)Text Generation using Recurrent Long Short Term Memory NetworkMachine Translation with Transformer in PythonBuilding a Rule-Based Chatbot with Natural Language ProcessingText Classification using scikit-learn in NLPText Summarization using HuggingFace ModelNatural Language Processing Interview QuestionData Science LiveCourse'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Introduction to Langsmith\\n\\n\\n\\nLast Updated : \\n23 Jul, 2025\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\n\\n1 Likes\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReport'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"Langsmith is a framework designed to enhance and streamline the development of natural language processing (NLP) applications. It builds upon LangChain, a popular library for chaining multiple language models together, to create complex and flexible NLP workflows. Langsmith provides tools for managing, deploying, and scaling NLP applications efficiently.What is Langsmith?Langsmith is a comprehensive solution for developers and data scientists working with NLP models. It offers a robust environment for creating, testing and deploying language models in a maintainable manner. By leveraging LangChain's capabilities, Langsmith simplifies the process of chaining multiple language models and other NLP components to build powerful applications.Key Features of Langsmith:Model Management: Easily manage multiple versions of your language models, track their performance and update them seamlessly.Workflow Structure: Design complex NLP workflows using a visual interface or code, enabling the\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='manage multiple versions of your language models, track their performance and update them seamlessly.Workflow Structure: Design complex NLP workflows using a visual interface or code, enabling the integration of various models and services.Deployment: Deploy models and workflows to different environments with minimal configuration.Scalability: Scale your applications horizontally to handle large data and requests.Monitoring and Logging: Keep track of model performance, usage statistics, and error logs for better observability.Integration with LangChainLangChain is a core component of Langsmith. It provides the foundational capabilities for chaining multiple language models. By integrating LangChain, Langsmith allows developers to create intricate NLP workflows that can perform various tasks, from text generation to sentiment analysis.Example: Building a Simple NLP Workflow1. Importing and Initializing Langchain'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Python'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='from langchain import LangChain\\nchain = LangChain()\\n\\n2. Added Language ModelsTwo models are added:\\'gpt-3\\' : A generative model\\'sentiment-analysis\\' : A classifier model\\nPython\\n\\nchain.add_model(\\'gpt-3\\', \\'text-davinci-003\\')\\nchain.add_model(\\'sentiment-analysis\\', \\'distilbert-base-uncased\\')\\n\\n3. Initializing LangsmithLangsmith is initialized by wrapping around the LangChain workflow.It adds functionalities like logging, monitoring, version control etc.\\nPython\\n\\nfrom langsmith import Langsmith\\nsmith = Langsmith(chain)\\n\\n4. Defining the NLP Workflow\\nPython\\n\\ndef nlp_workflow(text):\\n    generated_text = smith.run_model(\\'gpt-3\\', text)\\n    sentiment = smith.run_model(\\'sentiment-analysis\\', generated_text)\\n    return generated_text, sentiment\\n\\n5. Testing the workflow and Printing results\\nPython\\n\\ntext = \"Langsmith is revolutionizing NLP development!\"\\ngenerated_text, sentiment = nlp_workflow(text)\\n\\nprint(f\"Generated Text: {generated_text}\")\\nprint(f\"Sentiment: {sentiment}\")'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Output:Generated Text: \"Indeed, the advancements in NLP tools like Langsmith are paving the way for more efficient and effective language processing solutions, enhancing the capabilities of various applications.\"Sentiment: PositiveRelated Tools: LangGraph, LangFlow, LangServe, and LangFuseLangsmith is part of a broader ecosystem of tools designed to work together to enhance NLP workflows. Here’s a detailed look at these related tools:LangGraphLangGraph is a visualization tool that allows developers to explore and analyze the structure of language models and their workflows. With LangGraph, you can:Visualize Model Relationships: Understand how different models and components in your workflow are interconnected.Track Data Flow: See how data moves through the workflow, from input to output, and identify potential bottlenecks or inefficiencies.Debug and Optimize: Use visual insights to debug issues and optimize the performance of your NLP workflows.LangFlowIt is a workflow automation tool'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='identify potential bottlenecks or inefficiencies.Debug and Optimize: Use visual insights to debug issues and optimize the performance of your NLP workflows.LangFlowIt is a workflow automation tool that integrates seamlessly with Langsmith, enabling developers to design, manage and automate complex NLP workflows through a visual interface. LangFlow’s features include:Drag-and-Drop Interface: Easily create and modify workflows using a user-friendly drag-and-drop interface.Pre-Built Templates: Access a library of pre-built templates for common NLP tasks, speeding up the development process.Real-Time Monitoring: Monitor the performance and status of your workflows in real time, allowing for immediate adjustments and improvements.LangServeLangServe is a deployment tool specifically designed for serving NLP models and workflows in production environments. With LangServe, you can:Deploy at Scale: Efficiently deploy models to handle high volumes of requests, ensuring robust and scalable NLP'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='serving NLP models and workflows in production environments. With LangServe, you can:Deploy at Scale: Efficiently deploy models to handle high volumes of requests, ensuring robust and scalable NLP applications.Manage Deployments: Easily manage multiple deployments, track their performance, and update models without downtime.Secure and Reliable: Ensure the security and reliability of your deployed models with built-in features for authentication, authorization, and monitoring.LangFuseLangFuse is a tool for integrating multiple NLP models and services, enabling seamless interoperability across different components. LangFuse offers:Unified API: Provide a unified API to integrate various NLP models and services, simplifying the development process.Flexible Integration: Support for integrating models from different frameworks and languages, making it easier to build comprehensive NLP solutions.Enhanced Collaboration: Facilitate collaboration among team members by providing a centralized'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"models from different frameworks and languages, making it easier to build comprehensive NLP solutions.Enhanced Collaboration: Facilitate collaboration among team members by providing a centralized platform for managing and accessing integrated models.Applications of LangsmithLangsmith, with its framework and integration capabilities, has a wide range of applications across various industries. By leveraging Langsmith, organizations can build sophisticated NLP solutions that streamline operations, enhance user experiences and drive innovation. Here are some key applications of Langsmith:1. Customer Support and ChatbotsLangsmith can be used to develop intelligent customer support systems and chatbots that provide accurate responses to customer queries.Build chatbots that can handle common customer inquiries, reducing the need for human intervention and improving response times.2. Content Generation and SummarizationLangsmith's capabilities in text generation make it an excellent tool for\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"inquiries, reducing the need for human intervention and improving response times.2. Content Generation and SummarizationLangsmith's capabilities in text generation make it an excellent tool for content creation and summarization.Generating high-quality articles, blog posts and reports automatically, saving time and resources.3. Healthcare and Medical ResearchIn the healthcare industry, Langsmith can be used to process and analyze vast amounts of medical data, aiding in research and patient care.Analyzing patient records to extract valuable insights, identify patterns, and assist in diagnosis.4. Finance and BankingLangsmith can enhance various financial services by providing intelligent solutions for data analysis, customer interaction, and risk management.Analyzing transaction data to identify suspicious activities and potential fraud in real time.5. E-commerce and RetailIn the e-commerce and retail sector, Langsmith can improve customer experiences and streamline operations.Develop\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content=\"suspicious activities and potential fraud in real time.5. E-commerce and RetailIn the e-commerce and retail sector, Langsmith can improve customer experiences and streamline operations.Develop recommendation systems that suggest products based on customer behavior and preferences.Langsmith offers a powerful and flexible environment for developing and deploying NLP applications. By building on LangChain's capabilities, Langsmith provides a comprehensive solution for managing the entire lifecycle of NLP models, from development to deployment.\"),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Create Quiz\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Comment\\r\\n    \\n\\n\\n\\n\\n\\nY\\n\\n\\n\\n\\n\\nyashdkadam\\n\\n\\n\\n\\n\\n Follow\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\nImprove\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nY\\n\\n\\n\\n\\n \\n\\nyashdkadam \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\nArticle Tags : \\n\\n\\nNLP\\n\\n\\nAI-ML-DS\\n\\n\\nArtificial Intelligence\\n\\n\\nAI-ML-DS With Python\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n356k+ interested Geeks \\n\\n\\n\\nData Structures & Algorithms in Python - Self Paced \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4k+ interested Geeks \\n\\n\\n\\nGATE CS/IT 2027 Complete Course [with Placement Preparation] \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10k+ interested Geeks \\n\\n\\n\\nGATE 2027 - CS & IT  (Live + Recorded) \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate & Communications Address:\\n\\r\\n                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Corporate & Communications Address:\\n\\r\\n                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \\n\\n\\n\\n\\n\\nRegistered Address:\\r\\n                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalPrivacy PolicyCareersContact UsCorporate SolutionCampus Training ProgramExplorePOTDJob-A-ThonConnectBlogsNation Skill UpTutorialsProgramming LanguagesDSAWeb TechnologyAI, ML & Data ScienceDevOpsCS Core SubjectsGATESchool SubjectsSoftware and ToolsCoursesIBM CertificationDSA and PlacementsWeb DevelopmentData ScienceProgramming LanguagesDevOps & CloudGATETrending TechnologiesOffline CentersNoidaBengaluruPuneHyderabadPatnaPreparation CornerInterview CornerAptitudePuzzlesGfG 160System Design \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/nlp/introduction-to-langsmith/', 'title': 'Introduction to Langsmith - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\nmin 4 words, max Words Limit:1000\\n\\n\\n\\n\\nThank You!\\nYour suggestions are valuable to us.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide document into chunk\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "document=text_splitter.split_documents(docs)\n",
    "document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481b89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding=OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a776fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# vector database\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m----> 3\u001b[0m vectorstoreDB\u001b[38;5;241m=\u001b[39m\u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m vectorstoreDB\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:808\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    806\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 808\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:625\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    624\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(\n\u001b[0;32m    626\u001b[0m     texts, engine\u001b[38;5;241m=\u001b[39mengine, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    627\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:514\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 514\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_kwargs\n\u001b[0;32m    516\u001b[0m     )\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    518\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\langenv\\lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# vector database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoreDB=FAISS.from_documents(documents=document,embedding=embedding)\n",
    "\n",
    "vectorstoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab0a783",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstoreDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# write query from a vector db\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey Features of Langsmith:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mvectorstoreDB\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m      4\u001b[0m result[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstoreDB' is not defined"
     ]
    }
   ],
   "source": [
    "# write query from a vector db\n",
    "query=\"Key Features of Langsmith:\"\n",
    "result=vectorstoreDB.similarity_search(query=query)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366c10f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# retrival chain,document chain\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "# retrival chain,document chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9adda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bac04e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImport successful!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate(\n",
    "    \"\"\" \n",
    "        Answer the following question based only on the provided context\":\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e150ea1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdocument_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey Features of Langsmith:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m:[Document(page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey Features of Langsmith:Model Management: Easily manage multiple versions of your language models, track their performance and update them seamlesslyWorkflow Structure: Design complex NLP workflows using a visual interface or code, enabling the integration of various models and services.Deployment: Deploy models and workflows to different environments with minimal configuration.Scalability: Scale your applications horizontally to handle large data and requests.Monitoring and Logging: Keep track of model performance, usage statistics, and error logs for better observability. \u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      5\u001b[0m }) \u001b[38;5;66;03m# i have add context manually\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_chain' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"Key Features of Langsmith:\",\n",
    "    \"context\":[Document(page_content=\"Key Features of Langsmith:Model Management: Easily manage multiple versions of your language models, track their performance and update them seamlesslyWorkflow Structure: Design complex NLP workflows using a visual interface or code, enabling the integration of various models and services.Deployment: Deploy models and workflows to different environments with minimal configuration.Scalability: Scale your applications horizontally to handle large data and requests.Monitoring and Logging: Keep track of model performance, usage statistics, and error logs for better observability. \")]\n",
    "}) # i have add context manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d9906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f3817d",
   "metadata": {},
   "source": [
    "### however we want the document to first come from the retiever we just set up.That way , we can use the retriever to dynamically select the moset relevant document and pass those in far a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf4b80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstoreDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Retriever\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# it is a interface and resplsible to get\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#  the data to query from vectorstoreDB even we dont do similarity search\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mvectorstoreDB\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstoreDB' is not defined"
     ]
    }
   ],
   "source": [
    "## Retriever\n",
    "# it is a interface and resplsible to get\n",
    "#  the data to query from vectorstoreDB even we dont do similarity search\n",
    "retiever=vectorstoreDB.as_retriever()\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "retiever_chian=create_retrieval_chain(retiever,document_chain)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca93c52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retiever_chian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get the response from the llm\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mretiever_chian\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retiever_chian' is not defined"
     ]
    }
   ],
   "source": [
    "# get the response from the llm\n",
    "responce=retiever_chian.invoke({\"input\":\"Key Features of Langsmith\"})\n",
    "respnce[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "responce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
